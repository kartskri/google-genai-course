{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"day-2-classifying-embeddings-with-keras.ipynb","toc_visible":true},"google":{"image_path":"/examples/train_text_classifier_embeddings_files/output_3ae76701e178_0.png","keywords":["examples","googleai","samplecode","python","embed"]},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##### Copyright 2024 Google LLC.","metadata":{"id":"v0WeWbFNkUSz"}},{"cell_type":"code","source":"# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.","metadata":{"cellView":"form","id":"Aqwsgz9lkUst","execution":{"iopub.status.busy":"2024-11-08T20:12:05.315901Z","iopub.execute_input":"2024-11-08T20:12:05.316321Z","iopub.status.idle":"2024-11-08T20:12:05.338383Z","shell.execute_reply.started":"2024-11-08T20:12:05.316282Z","shell.execute_reply":"2024-11-08T20:12:05.337083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Day 2 - Classifying embeddings with Keras and the Gemini API\n\n## Overview\n\nWelcome back to the Kaggle 5-day Generative AI course. In this notebook, you'll learn to use the embeddings produced by the Gemini API to train a model that can classify newsgroup posts into the categories (the newsgroup itself) from the post contents.\n\nThis technique uses the Gemini API's embeddings as input, avoiding the need to train on text input directly, and as a result it is able to perform quite well using relatively few examples compared to training a text model from scratch.\n\n## For help\n\n**Common issues are covered in the [FAQ and troubleshooting guide](https://www.kaggle.com/code/markishere/day-0-troubleshooting-and-faqs).**\n","metadata":{"id":"bhT1u-Pof10V"}},{"cell_type":"code","source":"%pip install -U -q \"google-generativeai>=0.8.3\"","metadata":{"id":"FXq0ygI3BCdQ","execution":{"iopub.status.busy":"2024-11-12T21:37:50.993177Z","iopub.execute_input":"2024-11-12T21:37:50.993627Z","iopub.status.idle":"2024-11-12T21:38:25.166467Z","shell.execute_reply.started":"2024-11-12T21:37:50.993584Z","shell.execute_reply":"2024-11-12T21:38:25.164995Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import google.generativeai as genai","metadata":{"id":"XiJjB2vWCQJP","execution":{"iopub.status.busy":"2024-11-12T21:39:29.590569Z","iopub.execute_input":"2024-11-12T21:39:29.591044Z","iopub.status.idle":"2024-11-12T21:39:30.950026Z","shell.execute_reply.started":"2024-11-12T21:39:29.590999Z","shell.execute_reply":"2024-11-12T21:39:30.948496Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### Set up your API key\n\nTo run the following cell, your API key must be stored it in a [Kaggle secret](https://www.kaggle.com/discussions/product-feedback/114053) named `GOOGLE_API_KEY`.\n\nIf you don't already have an API key, you can grab one from [AI Studio](https://aistudio.google.com/app/apikey). You can find [detailed instructions in the docs](https://ai.google.dev/gemini-api/docs/api-key).\n\nTo make the key available through Kaggle secrets, choose `Secrets` from the `Add-ons` menu and follow the instructions to add your key or enable it for this notebook.","metadata":{"id":"_mwJYXpElYJc"}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\ngenai.configure(api_key=GOOGLE_API_KEY)","metadata":{"id":"tayrk_A2lZ7A","execution":{"iopub.status.busy":"2024-11-12T21:40:05.376742Z","iopub.execute_input":"2024-11-12T21:40:05.377276Z","iopub.status.idle":"2024-11-12T21:40:05.541268Z","shell.execute_reply.started":"2024-11-12T21:40:05.377223Z","shell.execute_reply":"2024-11-12T21:40:05.539980Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"If you received an error response along the lines of `No user secrets exist for kernel id ...`, then you need to add your API key via `Add-ons`, `Secrets` **and** enable it.\n\n![Screenshot of the checkbox to enable GOOGLE_API_KEY secret](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_3.png)","metadata":{"id":"c79728739642"}},{"cell_type":"markdown","source":"## Dataset\n\nThe [20 Newsgroups Text Dataset](https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html) contains 18,000 newsgroups posts on 20 topics divided into training and test sets. The split between the training and test datasets are based on messages posted before and after a specific date. For this tutorial, you will use sampled subsets of the training and test sets, and perform some processing using Pandas.","metadata":{"id":"C5B9sWq0hNEV"}},{"cell_type":"code","source":"from sklearn.datasets import fetch_20newsgroups\n\nnewsgroups_train = fetch_20newsgroups(subset=\"train\")\nnewsgroups_test = fetch_20newsgroups(subset=\"test\")\n\n# View list of class names for dataset\nnewsgroups_train.target_names","metadata":{"id":"jDoKis4om-Ea","execution":{"iopub.status.busy":"2024-11-12T21:40:09.707687Z","iopub.execute_input":"2024-11-12T21:40:09.708128Z","iopub.status.idle":"2024-11-12T21:40:21.451357Z","shell.execute_reply.started":"2024-11-12T21:40:09.708084Z","shell.execute_reply":"2024-11-12T21:40:21.450147Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"['alt.atheism',\n 'comp.graphics',\n 'comp.os.ms-windows.misc',\n 'comp.sys.ibm.pc.hardware',\n 'comp.sys.mac.hardware',\n 'comp.windows.x',\n 'misc.forsale',\n 'rec.autos',\n 'rec.motorcycles',\n 'rec.sport.baseball',\n 'rec.sport.hockey',\n 'sci.crypt',\n 'sci.electronics',\n 'sci.med',\n 'sci.space',\n 'soc.religion.christian',\n 'talk.politics.guns',\n 'talk.politics.mideast',\n 'talk.politics.misc',\n 'talk.religion.misc']"},"metadata":{}}]},{"cell_type":"code","source":"type(newsgroups_train)","metadata":{"execution":{"iopub.status.busy":"2024-11-12T21:40:31.066466Z","iopub.execute_input":"2024-11-12T21:40:31.066961Z","iopub.status.idle":"2024-11-12T21:40:31.074610Z","shell.execute_reply.started":"2024-11-12T21:40:31.066891Z","shell.execute_reply":"2024-11-12T21:40:31.073195Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"sklearn.utils._bunch.Bunch"},"metadata":{}}]},{"cell_type":"markdown","source":"Here is an example of what a record from the training set looks like.","metadata":{"id":"hDz9MjkNl_FD"}},{"cell_type":"code","source":"print(newsgroups_train.data[2])","metadata":{"id":"FPq-56AimOPX","execution":{"iopub.status.busy":"2024-11-12T21:40:56.307171Z","iopub.execute_input":"2024-11-12T21:40:56.307659Z","iopub.status.idle":"2024-11-12T21:40:56.314653Z","shell.execute_reply.started":"2024-11-12T21:40:56.307599Z","shell.execute_reply":"2024-11-12T21:40:56.313100Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"From: twillis@ec.ecn.purdue.edu (Thomas E Willis)\nSubject: PB questions...\nOrganization: Purdue University Engineering Computer Network\nDistribution: usa\nLines: 36\n\nwell folks, my mac plus finally gave up the ghost this weekend after\nstarting life as a 512k way back in 1985.  sooo, i'm in the market for a\nnew machine a bit sooner than i intended to be...\n\ni'm looking into picking up a powerbook 160 or maybe 180 and have a bunch\nof questions that (hopefully) somebody can answer:\n\n* does anybody know any dirt on when the next round of powerbook\nintroductions are expected?  i'd heard the 185c was supposed to make an\nappearence \"this summer\" but haven't heard anymore on it - and since i\ndon't have access to macleak, i was wondering if anybody out there had\nmore info...\n\n* has anybody heard rumors about price drops to the powerbook line like the\nones the duo's just went through recently?\n\n* what's the impression of the display on the 180?  i could probably swing\na 180 if i got the 80Mb disk rather than the 120, but i don't really have\na feel for how much \"better\" the display is (yea, it looks great in the\nstore, but is that all \"wow\" or is it really that good?).  could i solicit\nsome opinions of people who use the 160 and 180 day-to-day on if its worth\ntaking the disk size and money hit to get the active display?  (i realize\nthis is a real subjective question, but i've only played around with the\nmachines in a computer store breifly and figured the opinions of somebody\nwho actually uses the machine daily might prove helpful).\n\n* how well does hellcats perform?  ;)\n\nthanks a bunch in advance for any info - if you could email, i'll post a\nsummary (news reading time is at a premium with finals just around the\ncorner... :( )\n--\nTom Willis  \\  twillis@ecn.purdue.edu    \\    Purdue Electrical Engineering\n---------------------------------------------------------------------------\n\"Convictions are more dangerous enemies of truth than lies.\"  - F. W.\nNietzsche\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Start by preprocessing the data for this tutorial in a Pandas dataframe. To remove any sensitive information like names and email addresses, you will take only the subject and body of each message. This is an optional step that transforms the input data into more generic text, rather than email posts, so that it will work in other contexts.","metadata":{"id":"A9-DD7wgCx8j"}},{"cell_type":"code","source":"import email\nimport re\n\nimport pandas as pd\n\n\ndef preprocess_newsgroup_row(data):\n    # Extract only the subject and body\n    msg = email.message_from_string(data)\n    text = f\"{msg['Subject']}\\n\\n{msg.get_payload()}\"\n    # Strip any remaining email addresses\n    text = re.sub(r\"[\\w\\.-]+@[\\w\\.-]+\", \"\", text)\n    # Truncate each entry to 5,000 characters\n    text = text[:5000]\n\n    return text\n\n\ndef preprocess_newsgroup_data(newsgroup_dataset):\n    # Put data points into dataframe\n    df = pd.DataFrame(\n        {\"Text\": newsgroup_dataset.data, \"Label\": newsgroup_dataset.target}\n    )\n    # Clean up the text\n    df[\"Text\"] = df[\"Text\"].apply(preprocess_newsgroup_row)\n    # Match label to target name index\n    df[\"Class Name\"] = df[\"Label\"].map(lambda l: newsgroup_dataset.target_names[l])\n\n    return df","metadata":{"id":"urpLwp3UmPF3","execution":{"iopub.status.busy":"2024-11-12T21:42:30.203129Z","iopub.execute_input":"2024-11-12T21:42:30.203632Z","iopub.status.idle":"2024-11-12T21:42:30.713560Z","shell.execute_reply.started":"2024-11-12T21:42:30.203587Z","shell.execute_reply":"2024-11-12T21:42:30.712245Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Apply preprocessing function to training and test datasets\ndf_train = preprocess_newsgroup_data(newsgroups_train)\ndf_test = preprocess_newsgroup_data(newsgroups_test)\n\ndf_train.head()","metadata":{"id":"JMKddQdNnAOV","execution":{"iopub.status.busy":"2024-11-12T21:42:34.900834Z","iopub.execute_input":"2024-11-12T21:42:34.901486Z","iopub.status.idle":"2024-11-12T21:42:41.710089Z","shell.execute_reply.started":"2024-11-12T21:42:34.901441Z","shell.execute_reply":"2024-11-12T21:42:41.708846Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                                Text  Label  \\\n0  WHAT car is this!?\\n\\n I was wondering if anyo...      7   \n1  SI Clock Poll - Final Call\\n\\nA fair number of...      4   \n2  PB questions...\\n\\nwell folks, my mac plus fin...      4   \n3  Re: Weitek P9000 ?\\n\\nRobert J.C. Kyanko () wr...      1   \n4  Re: Shuttle Launch Question\\n\\nFrom article <>...     14   \n\n              Class Name  \n0              rec.autos  \n1  comp.sys.mac.hardware  \n2  comp.sys.mac.hardware  \n3          comp.graphics  \n4              sci.space  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Label</th>\n      <th>Class Name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>WHAT car is this!?\\n\\n I was wondering if anyo...</td>\n      <td>7</td>\n      <td>rec.autos</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SI Clock Poll - Final Call\\n\\nA fair number of...</td>\n      <td>4</td>\n      <td>comp.sys.mac.hardware</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>PB questions...\\n\\nwell folks, my mac plus fin...</td>\n      <td>4</td>\n      <td>comp.sys.mac.hardware</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Re: Weitek P9000 ?\\n\\nRobert J.C. Kyanko () wr...</td>\n      <td>1</td>\n      <td>comp.graphics</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Re: Shuttle Launch Question\\n\\nFrom article &lt;&gt;...</td>\n      <td>14</td>\n      <td>sci.space</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Next, you will sample some of the data by taking 100 data points in the training dataset, and dropping a few of the categories to run through this tutorial. Choose the science categories to compare.","metadata":{"id":"ogEGbg5XDv-T"}},{"cell_type":"code","source":"def sample_data(df, num_samples, classes_to_keep):\n    # Sample rows, selecting num_samples of each Label.\n    df = (\n        df.groupby(\"Label\")[df.columns]\n        .apply(lambda x: x.sample(num_samples))\n        .reset_index(drop=True)\n    )\n\n    df = df[df[\"Class Name\"].str.contains(classes_to_keep)]\n\n    # We have fewer categories now, so re-calibrate the label encoding.\n    df[\"Class Name\"] = df[\"Class Name\"].astype(\"category\")\n    df[\"Encoded Label\"] = df[\"Class Name\"].cat.codes\n\n    return df","metadata":{"id":"C2N7xXhJohLR","execution":{"iopub.status.busy":"2024-11-12T21:44:06.082168Z","iopub.execute_input":"2024-11-12T21:44:06.082810Z","iopub.status.idle":"2024-11-12T21:44:06.094812Z","shell.execute_reply.started":"2024-11-12T21:44:06.082680Z","shell.execute_reply":"2024-11-12T21:44:06.091705Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"TRAIN_NUM_SAMPLES = 100\nTEST_NUM_SAMPLES = 25\nCLASSES_TO_KEEP = \"sci\"  # Class name should contain 'sci' to keep science categories\n\ndf_train = sample_data(df_train, TRAIN_NUM_SAMPLES, CLASSES_TO_KEEP)\ndf_test = sample_data(df_test, TEST_NUM_SAMPLES, CLASSES_TO_KEEP)","metadata":{"id":"jS2g_ZGupBUb","execution":{"iopub.status.busy":"2024-11-12T21:44:09.087505Z","iopub.execute_input":"2024-11-12T21:44:09.088016Z","iopub.status.idle":"2024-11-12T21:44:09.145434Z","shell.execute_reply.started":"2024-11-12T21:44:09.087973Z","shell.execute_reply":"2024-11-12T21:44:09.144299Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"df_train.value_counts(\"Class Name\")","metadata":{"id":"j04TMPY8rV5q","execution":{"iopub.status.busy":"2024-11-12T21:44:13.615683Z","iopub.execute_input":"2024-11-12T21:44:13.616123Z","iopub.status.idle":"2024-11-12T21:44:13.631985Z","shell.execute_reply.started":"2024-11-12T21:44:13.616081Z","shell.execute_reply":"2024-11-12T21:44:13.630139Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"Class Name\nsci.crypt          100\nsci.electronics    100\nsci.med            100\nsci.space          100\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df_test.value_counts(\"Class Name\")","metadata":{"id":"qMsnfkVDsJlU","execution":{"iopub.status.busy":"2024-11-12T21:44:15.112949Z","iopub.execute_input":"2024-11-12T21:44:15.113427Z","iopub.status.idle":"2024-11-12T21:44:15.124567Z","shell.execute_reply.started":"2024-11-12T21:44:15.113353Z","shell.execute_reply":"2024-11-12T21:44:15.123220Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"Class Name\nsci.crypt          25\nsci.electronics    25\nsci.med            25\nsci.space          25\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"## Create the embeddings\n\nIn this section, you will generate embeddings for each piece of text using the Gemini API embeddings endpoint. To learn more about embeddings, visit the [embeddings guide](https://ai.google.dev/docs/embeddings_guide).\n\n**NOTE**: Embeddings are computed one at a time, so large sample sizes can take a long time!","metadata":{"id":"Kr-WlKzXjYWn"}},{"cell_type":"markdown","source":"### Task types\n\nThe `text-embedding-004` model supports a task type parameter that generates embeddings tailored for the specific task.\n\nTask Type | Description\n---       | ---\nRETRIEVAL_QUERY\t| Specifies the given text is a query in a search/retrieval setting.\nRETRIEVAL_DOCUMENT | Specifies the given text is a document in a search/retrieval setting.\nSEMANTIC_SIMILARITY\t| Specifies the given text will be used for Semantic Textual Similarity (STS).\nCLASSIFICATION\t| Specifies that the embeddings will be used for classification.\nCLUSTERING\t| Specifies that the embeddings will be used for clustering.\nFACT_VERIFICATION | Specifies that the given text will be used for fact verification.\n\nFor this example you will be performing classification.","metadata":{"id":"yPECMeE2xYA_"}},{"cell_type":"code","source":"from tqdm.auto import tqdm\n\ntqdm.pandas()\n\nfrom google.api_core import retry\n\n\n@retry.Retry(timeout=300.0)\ndef embed_fn(text: str) -> list[float]:\n    # You will be performing classification, so set task_type accordingly.\n    response = genai.embed_content(\n        model=\"models/text-embedding-004\", content=text, task_type=\"classification\"\n    )\n\n    return response[\"embedding\"]\n\n\ndef create_embeddings(df):\n    df[\"Embeddings\"] = df[\"Text\"].progress_apply(embed_fn)\n    return df","metadata":{"id":"MTBGKkPQsotz","execution":{"iopub.status.busy":"2024-11-12T21:44:23.080463Z","iopub.execute_input":"2024-11-12T21:44:23.081036Z","iopub.status.idle":"2024-11-12T21:44:23.090637Z","shell.execute_reply.started":"2024-11-12T21:44:23.080988Z","shell.execute_reply":"2024-11-12T21:44:23.089196Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"This code is optimised for clarity, and is not particularly fast. It is left as an exercise for the reader to implement [batch](https://ai.google.dev/api/embeddings#method:-models.batchembedcontents) or parallel/asynchronous embedding generation. Running this step will take some time.","metadata":{"id":"HVDwY8F2kW2O"}},{"cell_type":"code","source":"df_train = create_embeddings(df_train)\ndf_test = create_embeddings(df_test)","metadata":{"id":"AH0yrHUHtHtw","execution":{"iopub.status.busy":"2024-11-12T21:44:24.699761Z","iopub.execute_input":"2024-11-12T21:44:24.700201Z","iopub.status.idle":"2024-11-12T21:46:57.210312Z","shell.execute_reply.started":"2024-11-12T21:44:24.700151Z","shell.execute_reply":"2024-11-12T21:46:57.208917Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/400 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6ecaecc11e4405aa67fcc15fa65aefe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/100 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1d0372b83314d6bbbe4deb92b6993a2"}},"metadata":{}}]},{"cell_type":"code","source":"df_train.head()","metadata":{"id":"6G5TvLlmRjHc","execution":{"iopub.status.busy":"2024-11-12T21:47:36.073021Z","iopub.execute_input":"2024-11-12T21:47:36.073526Z","iopub.status.idle":"2024-11-12T21:47:36.097091Z","shell.execute_reply.started":"2024-11-12T21:47:36.073478Z","shell.execute_reply":"2024-11-12T21:47:36.095752Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"                                                   Text  Label Class Name  \\\n1100  Re: Don't fight Clipper Chip, subvert or repla...     11  sci.crypt   \n1101  Re: Fighting the Clipper Initiative\\n\\n (Phili...     11  sci.crypt   \n1102  What the clipper nay-sayers sound like to me.\\...     11  sci.crypt   \n1103  Re: Clipper chip -- technical details\\n\\n (D. ...     11  sci.crypt   \n1104  Re: Fifth Amendment and Passwords\\n\\nIn articl...     11  sci.crypt   \n\n      Encoded Label                                         Embeddings  \n1100              0  [-0.00707835, 0.02426387, -0.054541457, 0.0096...  \n1101              0  [0.005631752, 0.019081194, -0.041051492, 0.012...  \n1102              0  [-0.015669871, 0.0202, -0.041988097, 0.0081097...  \n1103              0  [0.00047533648, 0.028307443, -0.049179368, 0.0...  \n1104              0  [-0.016254159, 0.030583961, -0.04399911, 0.028...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Label</th>\n      <th>Class Name</th>\n      <th>Encoded Label</th>\n      <th>Embeddings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1100</th>\n      <td>Re: Don't fight Clipper Chip, subvert or repla...</td>\n      <td>11</td>\n      <td>sci.crypt</td>\n      <td>0</td>\n      <td>[-0.00707835, 0.02426387, -0.054541457, 0.0096...</td>\n    </tr>\n    <tr>\n      <th>1101</th>\n      <td>Re: Fighting the Clipper Initiative\\n\\n (Phili...</td>\n      <td>11</td>\n      <td>sci.crypt</td>\n      <td>0</td>\n      <td>[0.005631752, 0.019081194, -0.041051492, 0.012...</td>\n    </tr>\n    <tr>\n      <th>1102</th>\n      <td>What the clipper nay-sayers sound like to me.\\...</td>\n      <td>11</td>\n      <td>sci.crypt</td>\n      <td>0</td>\n      <td>[-0.015669871, 0.0202, -0.041988097, 0.0081097...</td>\n    </tr>\n    <tr>\n      <th>1103</th>\n      <td>Re: Clipper chip -- technical details\\n\\n (D. ...</td>\n      <td>11</td>\n      <td>sci.crypt</td>\n      <td>0</td>\n      <td>[0.00047533648, 0.028307443, -0.049179368, 0.0...</td>\n    </tr>\n    <tr>\n      <th>1104</th>\n      <td>Re: Fifth Amendment and Passwords\\n\\nIn articl...</td>\n      <td>11</td>\n      <td>sci.crypt</td>\n      <td>0</td>\n      <td>[-0.016254159, 0.030583961, -0.04399911, 0.028...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Build a simple classification model\n\nHere you will define a simple model that accepts the raw embedding data as input, has one hidden layer, and an output layer specifying the class probabilities. The prediction will correspond to the probability of a piece of text being a particular class of news.\n\nWhen you run the model, Keras will take care of details like shuffling the data points, calculating metrics and other ML boilerplate.","metadata":{"id":"QPYEYkIsWt_5"}},{"cell_type":"code","source":"import keras\nfrom keras import layers\n\n\ndef build_classification_model(input_size: int, num_classes: int) -> keras.Model:\n    return keras.Sequential(\n        [\n            layers.Input([input_size], name=\"embedding_inputs\"),\n            layers.Dense(input_size, activation=\"relu\", name=\"hidden\"),\n            layers.Dense(num_classes, activation=\"softmax\", name=\"output_probs\"),\n        ]\n    )","metadata":{"id":"3oLGi4w5JsQR","execution":{"iopub.status.busy":"2024-11-12T21:47:48.329365Z","iopub.execute_input":"2024-11-12T21:47:48.330518Z","iopub.status.idle":"2024-11-12T21:48:03.217831Z","shell.execute_reply.started":"2024-11-12T21:47:48.330467Z","shell.execute_reply":"2024-11-12T21:48:03.216159Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Derive the embedding size from observing the data. The embedding size can also be specified\n# with the `output_dimensionality` parameter to `embed_content` if you need to reduce it.\nembedding_size = len(df_train[\"Embeddings\"].iloc[0])\n\nclassifier = build_classification_model(\n    embedding_size, len(df_train[\"Class Name\"].unique())\n)\nclassifier.summary()\n\nclassifier.compile(\n    loss=keras.losses.SparseCategoricalCrossentropy(),\n    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n    metrics=[\"accuracy\"],\n)","metadata":{"id":"kORA1Akl5GsG","execution":{"iopub.status.busy":"2024-11-12T21:48:28.334122Z","iopub.execute_input":"2024-11-12T21:48:28.334952Z","iopub.status.idle":"2024-11-12T21:48:28.458521Z","shell.execute_reply.started":"2024-11-12T21:48:28.334899Z","shell.execute_reply":"2024-11-12T21:48:28.457305Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ hidden (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │       \u001b[38;5;34m590,592\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ output_probs (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │         \u001b[38;5;34m3,076\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ hidden (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,592</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ output_probs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,076</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m593,668\u001b[0m (2.26 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">593,668</span> (2.26 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m593,668\u001b[0m (2.26 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">593,668</span> (2.26 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"## Train the model\n\nFinally, you can train your model. This code uses early stopping to exit the training loop once the loss value stabilises, so the number of epoch loops executed may differ from the specified value.","metadata":{"id":"kbpTGGiMXDxl"}},{"cell_type":"code","source":"import numpy as np\n\n\nNUM_EPOCHS = 20\nBATCH_SIZE = 32\n\n# Split the x and y components of the train and validation subsets.\ny_train = df_train[\"Encoded Label\"]\nx_train = np.stack(df_train[\"Embeddings\"])\ny_val = df_test[\"Encoded Label\"]\nx_val = np.stack(df_test[\"Embeddings\"])\n\n# Specify that it's OK to stop early if accuracy stabilises.\nearly_stop = keras.callbacks.EarlyStopping(monitor=\"accuracy\", patience=3)\n\n# Train the model for the desired number of epochs.\nhistory = classifier.fit(\n    x=x_train,\n    y=y_train,\n    validation_data=(x_val, y_val),\n    callbacks=[early_stop],\n    batch_size=BATCH_SIZE,\n    epochs=NUM_EPOCHS,\n)","metadata":{"id":"bGgvMZGfJ1A4","execution":{"iopub.status.busy":"2024-11-12T21:48:36.351003Z","iopub.execute_input":"2024-11-12T21:48:36.351493Z","iopub.status.idle":"2024-11-12T21:48:40.913852Z","shell.execute_reply.started":"2024-11-12T21:48:36.351443Z","shell.execute_reply":"2024-11-12T21:48:40.912844Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Epoch 1/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.3460 - loss: 1.3635 - val_accuracy: 0.3700 - val_loss: 1.2928\nEpoch 2/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5817 - loss: 1.2135 - val_accuracy: 0.7100 - val_loss: 1.1512\nEpoch 3/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8834 - loss: 1.0102 - val_accuracy: 0.8300 - val_loss: 0.9981\nEpoch 4/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9342 - loss: 0.8085 - val_accuracy: 0.8600 - val_loss: 0.8483\nEpoch 5/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9517 - loss: 0.5898 - val_accuracy: 0.8500 - val_loss: 0.7166\nEpoch 6/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9604 - loss: 0.4675 - val_accuracy: 0.8600 - val_loss: 0.6123\nEpoch 7/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9546 - loss: 0.3400 - val_accuracy: 0.8700 - val_loss: 0.5333\nEpoch 8/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9811 - loss: 0.2609 - val_accuracy: 0.8700 - val_loss: 0.4797\nEpoch 9/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9653 - loss: 0.2202 - val_accuracy: 0.9400 - val_loss: 0.4272\nEpoch 10/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9833 - loss: 0.1890 - val_accuracy: 0.8700 - val_loss: 0.4020\nEpoch 11/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9961 - loss: 0.1524 - val_accuracy: 0.8800 - val_loss: 0.3797\nEpoch 12/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9874 - loss: 0.1378 - val_accuracy: 0.9000 - val_loss: 0.3728\nEpoch 13/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9831 - loss: 0.1079 - val_accuracy: 0.9300 - val_loss: 0.3428\nEpoch 14/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9993 - loss: 0.0981 - val_accuracy: 0.9100 - val_loss: 0.3329\nEpoch 15/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9927 - loss: 0.0922 - val_accuracy: 0.9200 - val_loss: 0.3169\nEpoch 16/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9875 - loss: 0.0759 - val_accuracy: 0.9400 - val_loss: 0.3084\nEpoch 17/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0630 - val_accuracy: 0.9300 - val_loss: 0.3111\nEpoch 18/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0631 - val_accuracy: 0.9500 - val_loss: 0.2924\nEpoch 19/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0514 - val_accuracy: 0.9300 - val_loss: 0.2923\nEpoch 20/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0564 - val_accuracy: 0.9500 - val_loss: 0.2865\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Evaluate model performance\n\nUse Keras <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/Model#evaluate\"><code>Model.evaluate</code></a> to calculate the loss and accuracy on the test dataset.","metadata":{"id":"xGBaDHZUPdJO"}},{"cell_type":"code","source":"classifier.evaluate(x=x_val, y=y_val, return_dict=True)","metadata":{"id":"d2kOeiqqQIB8","execution":{"iopub.status.busy":"2024-11-12T21:48:50.720728Z","iopub.execute_input":"2024-11-12T21:48:50.721187Z","iopub.status.idle":"2024-11-12T21:48:50.826139Z","shell.execute_reply.started":"2024-11-12T21:48:50.721141Z","shell.execute_reply":"2024-11-12T21:48:50.824980Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9446 - loss: 0.2676 \n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"{'accuracy': 0.949999988079071, 'loss': 0.286537766456604}"},"metadata":{}}]},{"cell_type":"markdown","source":"To learn more about training models with Keras, including how to visualise the model training metrics, read [Training & evaluation with built-in methods](https://www.tensorflow.org/guide/keras/training_with_built_in_methods).","metadata":{"id":"UyxMhiLYQXAN"}},{"cell_type":"markdown","source":"## Try a custom prediction\n\nNow that you have a trained model with good evaluation metrics, you can try to make a prediction with new, hand-written data. Use the provided example or try your own data to see how the model performs.","metadata":{"id":"XHyP-_torwsm"}},{"cell_type":"code","source":"# This example avoids any space-specific terminology to see if the model avoids\n# biases towards specific jargon.\nnew_text = \"\"\"\nFirst-timer looking to get out of here.\n\nHi, I'm writing about my interest in speaker with microchips who is travelling to the outer limits!\n\nWhat kind of craft can I buy? What is easiest to access from this 3rd rock?\n\nLet me know how to do that please.\n\"\"\"\nembedded = embed_fn(new_text)","metadata":{"id":"Lj4gR0Mdr2rb","execution":{"iopub.status.busy":"2024-11-12T21:51:07.936716Z","iopub.execute_input":"2024-11-12T21:51:07.937217Z","iopub.status.idle":"2024-11-12T21:51:08.234726Z","shell.execute_reply.started":"2024-11-12T21:51:07.937171Z","shell.execute_reply":"2024-11-12T21:51:08.233340Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"# Remember that the model takes embeddings as input, and the input must be batched,\n# so here they are passed as a list to provide a batch of 1.\ninp = np.array([embedded])\n[result] = classifier.predict(inp)\n\nfor idx, category in enumerate(df_test[\"Class Name\"].cat.categories):\n    print(f\"{category}: {result[idx] * 100:0.2f}%\")","metadata":{"id":"CKTHEMrRsbcu","execution":{"iopub.status.busy":"2024-11-12T21:51:08.236972Z","iopub.execute_input":"2024-11-12T21:51:08.237964Z","iopub.status.idle":"2024-11-12T21:51:08.326221Z","shell.execute_reply.started":"2024-11-12T21:51:08.237897Z","shell.execute_reply":"2024-11-12T21:51:08.324803Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\nsci.crypt: 18.52%\nsci.electronics: 32.67%\nsci.med: 0.32%\nsci.space: 48.48%\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}